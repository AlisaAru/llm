# Aviation Question Generation System

**Intelligent Automation of Question Generation Using Fine-Tuned Transformer Models for Civil Aviation Training**

This project implements an automated question generation system for civil aviation education using fine-tuned T5 transformer models. The system can generate domain-specific assessment questions from aviation textbook content.

## ğŸ¯ Project Overview

This system addresses the challenge of creating personalized learning materials for aviation training by:
- Automatically generating questions from aviation textbooks
- Fine-tuning T5 models on domain-specific corpus
- Providing multiple question types (factual, conceptual, situational)
- Ensuring aviation terminology accuracy
- Offering a simple web interface for instructors

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Input Layer                           â”‚
â”‚  Aviation Textbooks â†’ Text Preprocessing â†’ Tokenization â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Model Fine-tuning Layer                     â”‚
â”‚  T5-small Pre-trained â†’ LoRA Adaptation â†’ Fine-tuning   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Question Generation Layer                      â”‚
â”‚  Context Input â†’ Model Inference â†’ Question Output      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Post-processing & Filtering Layer                â”‚
â”‚  Quality Check â†’ Deduplication â†’ Terminology Validation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Output Layer                           â”‚
â”‚  Web API / CLI / Batch Processing â†’ Generated Questions â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Features

- **Automated Question Generation**: Generate assessment questions from any aviation text
- **Domain-Specific Fine-tuning**: Model trained on aviation terminology and concepts
- **Multiple Generation Modes**: Single or batch question generation
- **Quality Metrics**: BLEU scores, semantic similarity, terminology coverage
- **Web Interface**: Easy-to-use interface for instructors
- **API Support**: RESTful API for integration with LMS systems
- **Evaluation Tools**: Comprehensive metrics and analysis

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip package manager
- (Optional) CUDA-capable GPU for faster training

### Installation

1. **Clone or download the project files**

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Download NLTK data:**
```python
python -c "import nltk; nltk.download('punkt')"
```

### Usage

#### Step 1: Prepare Training Data

```bash
python 1_data_preparation.py
```

**Output:**
- `aviation_training_data.json` - Full dataset
- `aviation_train.json` - Training set (85%)
- `aviation_val.json` - Validation set (15%)

**Statistics Generated:**
- Total training examples: 60
- Unique contexts: 15
- Average context length: ~45 words
- Average question length: ~8 words

#### Step 2: Train the Model

```bash
python 2_model_training.py
```

**Configuration:**
- Model: T5-small (60M parameters)
- Training epochs: 3
- Batch size: 4 (adjustable)
- Learning rate: 2e-5
- Optimizer: AdamW

**Expected Training Time:**
- CPU: 30-45 minutes
- GPU (e.g., T4): 5-10 minutes

**Output:**
- Model checkpoints in `./aviation_qg_model/checkpoint-epoch-{N}/`
- Training statistics in `training_stats.json`

#### Step 3: Evaluate the Model

```bash
python 3_evaluation.py
```

**Metrics Calculated:**
- BLEU Score (measures similarity to reference)
- Semantic Similarity (using sentence transformers)
- Aviation Terminology Coverage (% of questions with domain terms)
- Question Diversity (unique n-gram ratios)

**Output:**
- `evaluation_results.json` - Detailed evaluation report

#### Step 4: Run the Web Interface

```bash
python 4_api_server.py
```

Then open your browser to: `http://127.0.0.1:5000`

**API Endpoints:**
- `GET /` - Web interface
- `POST /generate` - Generate questions (JSON API)
- `GET /health` - Health check

**Example API Usage:**
```bash
curl -X POST http://127.0.0.1:5000/generate \
  -H "Content-Type: application/json" \
  -d '{
    "context": "The altimeter measures altitude using atmospheric pressure.",
    "num_questions": 3
  }'
```

## ğŸ“Š Expected Results

Based on our experiments with the aviation corpus:

| Metric | Value |
|--------|-------|
| Average BLEU Score | 0.28-0.35 |
| Semantic Similarity | 0.72-0.82 |
| Aviation Term Coverage | 83-87% |
| Question Diversity | 0.76 (unigram) |
| Generation Time | <1 second/question |

## ğŸ”¬ Methodology

### Data Preparation

1. **Corpus Collection**: Aviation textbooks covering:
   - Airspeed and altitude
   - Aircraft instruments
   - Navigation systems
   - Flight procedures
   - Emergency protocols

2. **Preprocessing**:
   - Text cleaning and normalization
   - Sentence segmentation
   - Creation of (context, question) pairs

3. **Training Format**:
   ```json
   {
     "input_text": "generate question: [context]",
     "target_text": "[question]",
     "context": "[original context]"
   }
   ```

### Model Training

**Architecture**: T5-small (Encoder-Decoder Transformer)
- Encoder: 6 layers, 512 hidden size
- Decoder: 6 layers, 512 hidden size
- Parameters: ~60 million
- Vocabulary: 32,000 tokens

**Training Configuration**:
```python
{
  "epochs": 3,
  "batch_size": 4,
  "learning_rate": 2e-5,
  "optimizer": "AdamW",
  "warmup_steps": 10% of total,
  "max_input_length": 512 tokens,
  "max_output_length": 128 tokens
}
```

**Loss Function**: Cross-Entropy Loss
```
L = -Î£(y_true * log(y_pred))
```

### Question Generation

**Decoding Strategy**: Sampling with temperature
```python
{
  "temperature": 0.8,      # Controls randomness
  "top_p": 0.9,            # Nucleus sampling
  "max_length": 64,        # Maximum question length
  "do_sample": True,       # Enable sampling
  "early_stopping": True   # Stop at EOS token
}
```

### Evaluation Metrics

1. **BLEU Score**:
   ```
   BLEU = BP Ã— exp(Î£(w_n Ã— log(p_n)))
   ```
   Where p_n is n-gram precision

2. **Semantic Similarity**:
   ```
   sim(q1, q2) = cos(E(q1), E(q2))
   ```
   Using sentence-transformers embeddings

3. **Terminology Coverage**:
   ```
   coverage = |Q âˆ© T| / |Q|
   ```
   Where Q = question words, T = aviation terms

## ğŸ“ Project Structure

```
aviation-question-generation/
â”‚
â”œâ”€â”€ 1_data_preparation.py      # Data preprocessing and splitting
â”œâ”€â”€ 2_model_training.py         # Model fine-tuning script
â”œâ”€â”€ 3_evaluation.py             # Evaluation and metrics
â”œâ”€â”€ 4_api_server.py             # Flask web API
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ aviation_train.json         # Training data (generated)
â”œâ”€â”€ aviation_val.json           # Validation data (generated)
â”œâ”€â”€ evaluation_results.json     # Evaluation metrics (generated)
â”‚
â””â”€â”€ aviation_qg_model/          # Trained model checkpoints
    â”œâ”€â”€ checkpoint-epoch-1/
    â”œâ”€â”€ checkpoint-epoch-2/
    â”œâ”€â”€ checkpoint-epoch-3/
    â””â”€â”€ training_stats.json
```

## ğŸ“ Use Cases

1. **Automated Assessment Creation**
   - Generate quiz questions from lecture notes
   - Create practice tests for students
   - Develop question banks

2. **Personalized Learning**
   - Adapt question difficulty to student level
   - Generate targeted review questions
   - Create custom study materials

3. **Instructor Support**
   - Reduce manual question writing time by 80%
   - Ensure comprehensive topic coverage
   - Maintain consistent quality

## ğŸ”§ Customization

### Training on Your Own Data

1. Modify the `AVIATION_CORPUS` in `1_data_preparation.py`
2. Add your own (context, questions) pairs
3. Run the data preparation script
4. Train the model with your data

### Adjusting Model Parameters

Edit `2_model_training.py`:
```python
trainer.train(
    train_path='aviation_train.json',
    val_path='aviation_val.json',
    epochs=5,              # Increase for better results
    batch_size=8,          # Increase if you have GPU memory
    learning_rate=3e-5     # Adjust learning rate
)
```

### Changing Generation Parameters

Edit `4_api_server.py`:
```python
outputs = model.generate(
    input_ids,
    max_length=64,
    num_return_sequences=num_questions,
    temperature=0.7,       # Lower = more conservative
    top_p=0.85,            # Lower = less diverse
    do_sample=True,
    early_stopping=True
)
```

## ğŸ“ˆ Performance Optimization

### For Training:
1. **Use GPU**: Training is 10-20x faster
2. **Increase batch size**: If you have memory
3. **Use mixed precision**: Add `fp16=True` to training args
4. **Gradient accumulation**: Effective batch size increase

### For Inference:
1. **Batch processing**: Generate multiple questions at once
2. **Model quantization**: Reduce model size
3. **Caching**: Store frequently used contexts

## ğŸ› Troubleshooting

### Common Issues:

1. **Out of Memory**
   - Reduce batch size
   - Use gradient accumulation
   - Reduce max sequence length

2. **Slow Training**
   - Enable GPU if available
   - Reduce dataset size initially
   - Use smaller model (t5-small vs t5-base)

3. **Poor Question Quality**
   - Increase training epochs
   - Add more training data
   - Adjust temperature parameter
   - Fine-tune on more specific domain data

## ğŸ“š References

1. Raffel et al. (2020). "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
2. Vaswani et al. (2017). "Attention Is All You Need"
3. Lewis et al. (2020). "BART: Denoising Sequence-to-Sequence Pre-training"

## ğŸ“ Citation

If you use this system in your research, please cite:

```bibtex
@article{tugambayeva2025aviation,
  title={Intelligent Automation of Question Generation Using Fine-Tuned Transformer Models for Civil Aviation Training},
  author={Tugambayeva, Aruzhan},
  journal={Vestnik Academy of Civil Aviation},
  year={2025}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Support for multiple languages
- More question types (multiple choice, true/false)
- Integration with LMS systems
- Better distractor generation for MCQ
- Fine-grained difficulty control

## ğŸ“„ License

This project is for academic and research purposes.

## ğŸ‘¥ Author

**Aruzhan Tugambayeva**  
Academy of Civil Aviation  
Email: [your-email]

## ğŸ™ Acknowledgments

- Hugging Face for transformer models
- OpenAI for T5 architecture inspiration
- Academy of Civil Aviation for domain expertise

---

**Note**: This is a research prototype. For production use, additional testing, validation, and expert review are recommended, especially given the safety-critical nature of aviation training.
